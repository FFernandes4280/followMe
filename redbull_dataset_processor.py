#!/usr/bin/env python3
"""
Processador de Dataset Red Bull para Detec√ß√£o de Pessoas em Esportes
Este script extrai frames dos v√≠deos do Red Bull e gera anota√ß√µes autom√°ticas.
"""

import os
import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import yaml
from sklearn.model_selection import train_test_split
import shutil
from typing import List, Tuple
import random

class RedBullDatasetProcessor:
    def __init__(self, redbull_dir="red-bull/src", output_dir="sports_data"):
        """
        Inicializa o processador do dataset Red Bull
        
        Args:
            redbull_dir (str): Diret√≥rio com os v√≠deos do Red Bull
            output_dir (str): Diret√≥rio de sa√≠da para o dataset
        """
        self.redbull_dir = Path(redbull_dir)
        self.output_dir = Path(output_dir)
        self.setup_directories()
        
        # Carrega modelo YOLO para detec√ß√£o de pessoas
        self.detection_model = YOLO("yolov8n.pt")
        
    def setup_directories(self):
        """Cria a estrutura de diret√≥rios necess√°ria"""
        directories = [
            self.output_dir / "images" / "train",
            self.output_dir / "images" / "val",
            self.output_dir / "images" / "test",
            self.output_dir / "labels" / "train",
            self.output_dir / "labels" / "val",
            self.output_dir / "labels" / "test",
            self.output_dir / "raw_frames",
            self.output_dir / "annotations"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            print(f"‚úì Diret√≥rio criado: {directory}")
    
    def extract_frames_from_videos(self, frame_interval: int = 30, max_frames_per_video: int = 100):
        """
        Extrai frames dos v√≠deos do Red Bull
        
        Args:
            frame_interval (int): Intervalo entre frames (a cada N frames)
            max_frames_per_video (int): M√°ximo de frames por v√≠deo
        """
        print("üé¨ Extraindo frames dos v√≠deos do Red Bull...")
        
        video_files = list(self.redbull_dir.glob("*.mp4"))
        print(f"üìπ Encontrados {len(video_files)} v√≠deos")
        
        total_frames = 0
        
        for video_path in video_files:
            print(f"\nüé• Processando: {video_path.name}")
            
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                print(f"‚ùå Erro ao abrir v√≠deo: {video_path}")
                continue
            
            frame_count = 0
            extracted_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Extrai frame a cada frame_interval frames
                if frame_count % frame_interval == 0:
                    # Redimensiona frame para 640x640
                    frame_resized = cv2.resize(frame, (640, 640))
                    
                    # Salva frame
                    frame_filename = f"{video_path.stem}_frame_{frame_count:06d}.jpg"
                    frame_path = self.output_dir / "raw_frames" / frame_filename
                    cv2.imwrite(str(frame_path), frame_resized, [cv2.IMWRITE_JPEG_QUALITY, 70]) # <--- 70% de compress√£o JPEG
                    
                    extracted_count += 1
                    total_frames += 1
                    
                    if extracted_count >= max_frames_per_video:
                        break
                
                frame_count += 1
            
            cap.release()
            print(f"‚úì Extra√≠dos {extracted_count} frames de {video_path.name}")
        
        print(f"\n‚úÖ Total de frames extra√≠dos: {total_frames}")
        return total_frames
    
    def detect_persons_in_frames(self, confidence_threshold: float = 0.5):
        """
        Detecta pessoas nos frames extra√≠dos usando YOLO
        
        Args:
            confidence_threshold (float): Threshold de confian√ßa para detec√ß√µes
        """
        print("üîç Detectando pessoas nos frames...")
        
        frames_dir = self.output_dir / "raw_frames"
        frame_files = list(frames_dir.glob("*.jpg"))
        
        print(f"üìä Processando {len(frame_files)} frames...")
        
        detections_count = 0
        
        for i, frame_path in enumerate(frame_files):
            if i % 50 == 0:
                print(f"  Processando frame {i+1}/{len(frame_files)}")
            
            # Carrega frame
            frame = cv2.imread(str(frame_path))
            if frame is None:
                continue
            
            # Detecta pessoas
            results = self.detection_model(frame, conf=confidence_threshold, classes=[0]) # classe 0 = person
            
            # Processa detec√ß√µes
            annotations = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        # Converte coordenadas para formato YOLO
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        
                        # Normaliza coordenadas
                        img_height, img_width = frame.shape[:2]
                        center_x = (x1 + x2) / 2.0 / img_width
                        center_y = (y1 + y2) / 2.0 / img_height
                        width = (x2 - x1) / img_width
                        height = (y2 - y1) / img_height
                        
                        # Adiciona anota√ß√£o (classe 0 = person_sporting)
                        annotations.append(f"0 {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}")
            
            # Salva anota√ß√£o se houver detec√ß√µes
            if annotations:
                annotation_path = self.output_dir / "annotations" / f"{frame_path.stem}.txt"
                with open(annotation_path, 'w') as f:
                    f.write('\n'.join(annotations))
                detections_count += 1
        
        print(f"‚úÖ Detec√ß√µes encontradas em {detections_count} frames")
        return detections_count
    
    def organize_dataset(self, train_ratio: float = 0.7, val_ratio: float = 0.15, test_ratio: float = 0.15):
        """
        Organiza o dataset nos splits de treino, valida√ß√£o e teste
        
        Args:
            train_ratio (float): Propor√ß√£o para treino
            val_ratio (float): Propor√ß√£o para valida√ß√£o
            test_ratio (float): Propor√ß√£o para teste
        """
        print("üìÅ Organizando dataset...")
        
        # Lista frames com anota√ß√µes
        frames_dir = self.output_dir / "raw_frames"
        annotations_dir = self.output_dir / "annotations"
        
        valid_frames = []
        for frame_path in frames_dir.glob("*.jpg"):
            annotation_path = annotations_dir / f"{frame_path.stem}.txt"
            if annotation_path.exists():
                valid_frames.append(frame_path)
        
        print(f"üìä {len(valid_frames)} frames com anota√ß√µes v√°lidas")
        
        if len(valid_frames) == 0:
            print("‚ùå Nenhum frame com anota√ß√£o encontrado!")
            return
        
        # Divide em splits
        train_frames, temp_frames = train_test_split(
            valid_frames, 
            test_size=(val_ratio + test_ratio), 
            random_state=42
        )
        val_frames, test_frames = train_test_split(
            temp_frames, 
            test_size=test_ratio/(val_ratio + test_ratio), 
            random_state=42
        )
        
        print(f"üìà Divis√£o do dataset:")
        print(f"   Treino: {len(train_frames)} frames")
        print(f"   Valida√ß√£o: {len(val_frames)} frames")
        print(f"   Teste: {len(test_frames)} frames")
        
        # Copia arquivos para splits
        for split_name, frames in [("train", train_frames), ("val", val_frames), ("test", test_frames)]:
            for frame_path in frames:
                # Copia imagem
                dest_img = self.output_dir / "images" / split_name / frame_path.name
                shutil.copy2(frame_path, dest_img)
                
                # Copia anota√ß√£o
                annotation_path = annotations_dir / f"{frame_path.stem}.txt"
                dest_annotation = self.output_dir / "labels" / split_name / f"{frame_path.stem}.txt"
                shutil.copy2(annotation_path, dest_annotation)
        
        print("‚úÖ Dataset organizado com sucesso!")
    
    def create_dataset_config(self):
        """Cria arquivo de configura√ß√£o do dataset"""
        config = {
            'path': str(self.output_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': 1,
            'names': ['person_sporting']
        }
        
        config_path = self.output_dir / "dataset.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"‚úì Configura√ß√£o salva em: {config_path}")
        return config_path
    
    def validate_dataset(self):
        """Valida a integridade do dataset"""
        print("üîç Validando dataset...")
        
        issues = []
        
        for split in ['train', 'val', 'test']:
            images_dir = self.output_dir / "images" / split
            labels_dir = self.output_dir / "labels" / split
            
            # Conta arquivos
            image_files = list(images_dir.glob("*.jpg"))
            label_files = list(labels_dir.glob("*.txt"))
            
            print(f"  {split}: {len(image_files)} imagens, {len(label_files)} labels")
            
            # Verifica correspond√™ncia
            for img_file in image_files:
                label_file = labels_dir / f"{img_file.stem}.txt"
                if not label_file.exists():
                    issues.append(f"Label n√£o encontrado para {img_file.name} em {split}")
        
        if issues:
            print("‚ö†Ô∏è  Problemas encontrados:")
            for issue in issues:
                print(f"  - {issue}")
        else:
            print("‚úÖ Dataset validado com sucesso!")
        
        return len(issues) == 0
    
    def process_redbull_dataset(self, frame_interval: int = 30, max_frames_per_video: int = 100, 
                               confidence_threshold: float = 0.5):
        """
        Processa completamente o dataset do Red Bull
        
        Args:
            frame_interval (int): Intervalo entre frames
            max_frames_per_video (int): M√°ximo de frames por v√≠deo
            confidence_threshold (float): Threshold de confian√ßa para detec√ß√µes
        """
        print("üèÉ‚Äç‚ôÇÔ∏è Processando Dataset Red Bull para Detec√ß√£o de Pessoas em Esportes")
        print("=" * 70)
        
        # 1. Extrai frames dos v√≠deos
        print("\n1Ô∏è‚É£ Extraindo frames...")
        total_frames = self.extract_frames_from_videos(frame_interval, max_frames_per_video)
        
        if total_frames == 0:
            print("‚ùå Nenhum frame extra√≠do!")
            return False
        
        # 2. Detecta pessoas nos frames
        print("\n2Ô∏è‚É£ Detectando pessoas...")
        detections = self.detect_persons_in_frames(confidence_threshold)
        
        if detections == 0:
            print("‚ùå Nenhuma pessoa detectada!")
            return False
        
        # 3. Organiza dataset
        print("\n3Ô∏è‚É£ Organizando dataset...")
        self.organize_dataset()
        
        # 4. Cria configura√ß√£o
        print("\n4Ô∏è‚É£ Criando configura√ß√£o...")
        self.create_dataset_config()
        
        # 5. Valida dataset
        print("\n5Ô∏è‚É£ Validando dataset...")
        is_valid = self.validate_dataset()
        
        if is_valid:
            print("\n‚úÖ Dataset Red Bull processado com sucesso!")
            print("üìÅ Estrutura criada:")
            print(f"  - {self.output_dir}/images/ (train, val, test)")
            print(f"  - {self.output_dir}/labels/ (train, val, test)")
            print(f"  - {self.output_dir}/dataset.yaml")
            return True
        else:
            print("\n‚ùå Dataset com problemas!")
            return False

def main():
    """Fun√ß√£o principal"""
    # Inicializa processador
    processor = RedBullDatasetProcessor()
    
    # Processa dataset
    success = processor.process_redbull_dataset(
        frame_interval=1,          # Extrai todos os frames do v√≠deo (1 frame por frame)
        max_frames_per_video=3600, # M√°ximo 3600 frames por v√≠deo (2 minutos de v√≠deo)
        confidence_threshold=0.4   # Threshold de confian√ßa para detec√ß√µes
    )
    
    if success:
        print("\nüöÄ Dataset pronto para treinamento!")
        print("Execute: python sports_detection_training.py")
    else:
        print("\n‚ùå Falha no processamento do dataset!")

if __name__ == "__main__":
    main()
